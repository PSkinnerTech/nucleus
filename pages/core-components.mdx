# Core Components

## üß† 2. Core Components (with Roles)

### üó£Ô∏è Voice Layer

Handles all real-time input/output via audio interfaces.
- Omi Wearable: Wake-word detection, always-on microphone, and speaker for continuous interaction
- STT Engine: Converts spoken input to text (e.g., Whisper, Deepgram)
- TTS Engine: Converts textual responses into natural voice replies (primary: Google Cloud TTS, offline fallback: Coqui TTS)
- Wake Word / Toggle System: Activates listening mode and toggles always-on functionality via specific voice commands

---

### üß† Rin Core AI (Orchestration Engine)

The brain of Rin, coordinating tasks, managing context, and driving personality.
- Prompt Router + Task Dispatcher: Analyzes intent and routes the request to the right sub-agent or API
- Personality Module: Adjusts tone, language, and behavior of responses based on user-defined settings (e.g., calm, funny, formal)
- Agent Orchestrator:
  - Runs background tasks via Celery workers
  - Schedules agent chains for multi-step tasks
  - Shares memory and context between agents
- RLHF Feedback Trainer: Learns from user feedback ("Yes, that's correct" / "That's wrong") to refine behavior over time
- Agent Permissions System: Allows or requires approval before autonomous agents execute tasks (e.g., sending emails, booking services)
- **Model Routing with Manual Override:** Smart auto-routing with optional manual override per task for advanced user control.

---

### üß© MCP Server + Context Engine

Maintains awareness and history across interactions and sessions.
- Model Context Protocol (MCP): Tracks conversation threads, goals, and context across multiple agents and sessions
- Session Memory: Ephemeral, per-session memory for fast context without long-term storage
- Long-Term Memory Store: Persistent knowledge using vector or hybrid databases (Chroma, Weaviate, or PostgreSQL)

---

### üß† LLM Access & Model Tools

Interfaces with large language models and handles smart routing for inference tasks.
- LangChain/LiteLLM Router: Primary gateway for smart model routing (short/long context, code vs. natural language)
  - Fast queries ‚Üí Claude, Sonar
  - Complex tasks ‚Üí GPT-4, Claude 2.1, Haiku
  - Code generation ‚Üí Claude 2.1, GPT-4
- Local Model Fallback (e.g., Ollama): Ensures Rin can function offline or in privacy-concerned contexts

---

### üîå API Integration Layer

Provides connectivity to external services and platforms.
- Calendars: Google Calendar, Outlook
- Email: Gmail, Outlook APIs (OAuth2 auth)
- Messaging: Telegram, Discord, SMS (Twilio)
- Social Media: X (Twitter), LinkedIn, Instagram (via official or third-party APIs)
- Services & Errands: UberEats, Rappi, Amazon, flight/hotel APIs
- Automation Bridges: IFTTT, Zapier, Python scripting, Home Assistant

---

### üîí Security & Identity Layer

Ensures privacy, secure access, and proper identity verification.
- Token Vault: Secure storage of API credentials (e.g., HashiCorp Vault, Python-keyring)
- Auth Abstraction: OAuth2 for third-party logins, session handling
- Fallback Authentication: Voiceprint ID or manual PIN/passphrase
- Local Data Encryption: Protects session and memory data stored on-device

---

### üñ•Ô∏è Hosting & Interface Layer

Defines where Rin lives and how you interact with it.
- Hybrid Hosting Model: Self-hosted MCP/memory + optionally managed LLMs (or fully local/offline mode)
- Frontend Interface (optional): Web dashboard (React + Tailwind) or desktop/native GUI via PyQt/Tkinter

--- 